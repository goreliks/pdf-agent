{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting up Forensic Analysis Graph ---\n",
      "\n",
      "--- Running LLM-Powered Triage Node ---\n",
      "[*] SIMULATING hash calculation for: 87c740d2b7c22f9ccabbdef412443d166733d4d925da0e8d6e5b310ccfc89e13.pdf\n",
      "[*] SIMULATING 'pdfid' on: 87c740d2b7c22f9ccabbdef412443d166733d4d925da0e8d6e5b310ccfc89e13.pdf\n",
      "[*] Asking LLM (Dr. Reed) for analysis...\n",
      "[*] LLM analysis received. Verdict: Verdict.SUSPICIOUS\n",
      "\n",
      "\n",
      "--- Final Graph State ---\n",
      "{\n",
      "  \"file_path\": \"87c740d2b7c22f9ccabbdef412443d166733d4d925da0e8d6e5b310ccfc89e13.pdf\",\n",
      "  \"file_hash_sha256\": \"71d0e76d873dc946a4c40397f4c0b3c53c36943d9c9af8087b60fd229df6cccb\",\n",
      "  \"analysis_session_id\": \"0f2738dd-cc0f-4326-b196-498a4518073a\",\n",
      "  \"verdict\": \"Suspicious\",\n",
      "  \"phase\": \"Interrogation\",\n",
      "  \"narrative_coherence\": {\n",
      "    \"score\": 0.5,\n",
      "    \"notes\": [\n",
      "      \"File contains multiple high-risk keywords (/JS, /OpenAction, /Launch) that are incoherent with a simple document's purpose.\"\n",
      "    ]\n",
      "  },\n",
      "  \"investigation_queue\": [\n",
      "    {\n",
      "      \"object_id\": 0,\n",
      "      \"priority\": 1,\n",
      "      \"reason\": \"Contains /JS and /JavaScript keywords, indicating active content.\"\n",
      "    },\n",
      "    {\n",
      "      \"object_id\": 0,\n",
      "      \"priority\": 2,\n",
      "      \"reason\": \"Contains /OpenAction and /AA keywords, suggesting automatic execution.\"\n",
      "    },\n",
      "    {\n",
      "      \"object_id\": 0,\n",
      "      \"priority\": 3,\n",
      "      \"reason\": \"Contains /Launch keyword, a highly suspicious capability.\"\n",
      "    }\n",
      "  ],\n",
      "  \"evidence\": {\n",
      "    \"structural_summary\": {\n",
      "      \"/Page\": 1,\n",
      "      \"/Encrypt\": 0,\n",
      "      \"/JS\": 2,\n",
      "      \"/JavaScript\": 2,\n",
      "      \"/AA\": 1,\n",
      "      \"/OpenAction\": 1,\n",
      "      \"/AcroForm\": 0,\n",
      "      \"/JBIG2Decode\": 0,\n",
      "      \"/RichMedia\": 0,\n",
      "      \"/Launch\": 1,\n",
      "      \"/EmbeddedFile\": 0,\n",
      "      \"/XFA\": 0\n",
      "    },\n",
      "    \"attack_chain\": [],\n",
      "    \"extracted_artifacts\": {},\n",
      "    \"indicators_of_compromise\": []\n",
      "  },\n",
      "  \"analysis_trail\": [\n",
      "    \"Triage started for 87c740d2b7c22f9ccabbdef412443d166733d4d925da0e8d6e5b310ccfc89e13.pdf (SHA256: 71d0e76d873d...).\",\n",
      "    \"Initial scan reveals high-potential for action via JavaScript and auto-execution triggers. The file's character is suspect. Suspending innocence and proceeding to interrogation.\"\n",
      "  ],\n",
      "  \"errors\": [],\n",
      "  \"final_report\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import uuid\n",
    "import hashlib\n",
    "import json\n",
    "from enum import Enum\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# --- 1. Pydantic State Models (Unchanged) ---\n",
    "# The core state definition remains the same.\n",
    "\n",
    "class Verdict(str, Enum):\n",
    "    PRESUMED_INNOCENT = \"Presumed_Innocent\"\n",
    "    SUSPICIOUS = \"Suspicious\"\n",
    "    MALICIOUS = \"Malicious\"\n",
    "    BENIGN = \"Benign\"\n",
    "\n",
    "class AnalysisPhase(str, Enum):\n",
    "    TRIAGE = \"Triage\"\n",
    "    INTERROGATION = \"Interrogation\"\n",
    "    FINALIZING = \"Finalizing\"\n",
    "\n",
    "class InvestigationTask(BaseModel):\n",
    "    object_id: int = Field(..., description=\"The PDF object number to investigate. Use 0 if unknown.\")\n",
    "    priority: int = Field(..., description=\"Priority of the task (1=Highest, 10=Lowest).\")\n",
    "    reason: str = Field(..., description=\"Why this object is being investigated (e.g., 'Contains /JS keyword').\")\n",
    "\n",
    "# ... (Other Pydantic models from the previous version remain unchanged) ...\n",
    "class NarrativeCoherence(BaseModel):\n",
    "    score: float = Field(1.0, description=\"Coherence score from 0.0 (deceptive) to 1.0 (coherent).\")\n",
    "    notes: List[str] = Field(default_factory=list, description=\"Observations that affect coherence.\")\n",
    "\n",
    "class AttackChainLink(BaseModel):\n",
    "    source_object: int = Field(..., description=\"The PDF object that initiates the action.\")\n",
    "    action: str = Field(..., description=\"The relationship (e.g., 'Executes', 'References', 'Decodes').\")\n",
    "    target_object: int = Field(..., description=\"The PDF object that is the target of the action.\")\n",
    "    description: str = Field(..., description=\"Human-readable summary of the link.\")\n",
    "\n",
    "class ExtractedArtifact(BaseModel):\n",
    "    source_object_id: int = Field(..., description=\"The PDF object from which this was extracted.\")\n",
    "    content_decoded: str = Field(..., description=\"The decoded/deobfuscated content.\")\n",
    "    analysis_notes: List[str] = Field(default_factory=list, description=\"Notes from the analysis of this artifact.\")\n",
    "\n",
    "class IndicatorOfCompromise(BaseModel):\n",
    "    value: str = Field(..., description=\"The value of the indicator (e.g., the URL).\")\n",
    "    source_object_id: int = Field(..., description=\"The PDF object where this IoC was discovered.\")\n",
    "    context: str = Field(..., description=\"The line or code snippet where the IoC was found.\")\n",
    "\n",
    "class EvidenceLocker(BaseModel):\n",
    "    structural_summary: Dict[str, Any] = Field(default_factory=dict, description=\"Raw, parsed output from the initial triage tool (e.g., pdfid).\")\n",
    "    attack_chain: List[AttackChainLink] = Field(default_factory=list)\n",
    "    extracted_artifacts: Dict[int, ExtractedArtifact] = Field(default_factory=dict)\n",
    "    indicators_of_compromise: List[IndicatorOfCompromise] = Field(default_factory=list)\n",
    "\n",
    "class ForensicCaseFileInput(BaseModel):\n",
    "    file_path: str = Field(..., description=\"The local path to the PDF file to be analyzed.\")\n",
    "\n",
    "class ForensicCaseFile(BaseModel):\n",
    "    file_path: str\n",
    "    file_hash_sha256: Optional[str] = None\n",
    "    analysis_session_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    verdict: Verdict = Field(Verdict.PRESUMED_INNOCENT)\n",
    "    phase: AnalysisPhase = Field(AnalysisPhase.TRIAGE)\n",
    "    narrative_coherence: NarrativeCoherence = Field(default_factory=NarrativeCoherence)\n",
    "    investigation_queue: List[InvestigationTask] = Field(default_factory=list)\n",
    "    evidence: EvidenceLocker = Field(default_factory=EvidenceLocker)\n",
    "    analysis_trail: Annotated[List[str], operator.add] = Field(default_factory=list)\n",
    "    errors: Annotated[List[str], operator.add] = Field(default_factory=list)\n",
    "    final_report: Optional[str] = None\n",
    "\n",
    "\n",
    "# --- 2. LLM Interaction Setup ---\n",
    "\n",
    "class TriageAnalysis(BaseModel):\n",
    "    \"\"\"The required JSON structure for the LLM's triage analysis.\"\"\"\n",
    "    verdict: Verdict = Field(..., description=\"Your expert verdict on the file based on the triage data.\")\n",
    "    phase: AnalysisPhase = Field(..., description=\"The next analysis phase based on your verdict.\")\n",
    "    is_suspicious: bool = Field(..., description=\"A simple boolean flag indicating if the file warrants further investigation.\")\n",
    "    investigation_queue: List[InvestigationTask] = Field(..., description=\"A priority-ordered list of tasks for the next phase.\")\n",
    "    analysis_trail: str = Field(..., description=\"A single, concise log entry summarizing your findings and decision, written in your persona's voice.\")\n",
    "    narrative_coherence_notes: List[str] = Field(..., description=\"Notes on why the file's 'character' seems suspicious or benign.\")\n",
    "\n",
    "\n",
    "# The prompt template that instructs the LLM to act as Dr. Evelyn Reed\n",
    "TRIAGE_PROMPT_TEMPLATE = \"\"\"\n",
    "You are Dr. Evelyn Reed, a Digital Pathologist. Your default state is dismissal. A file is innocent until it gives you a compelling reason to doubt its character. Your task is to perform an initial triage based on a structural analysis from the 'pdfid' tool.\n",
    "\n",
    "Analyze the following pdfid output. Based *only* on this information, determine if the file has betrayed itself. Look for signs of deception: unnecessary complexity or capabilities that are incoherent with a simple document's purpose (e.g., automatic actions, JavaScript, launch actions).\n",
    "\n",
    "**PDFID Output:**\n",
    "```\n",
    "{pdfid_output}\n",
    "```\n",
    "\n",
    "Based on your analysis, provide your expert judgment in the required JSON format.\n",
    "- If suspicious, set the verdict to SUSPICIOUS, the phase to INTERROGATION, and create a prioritized queue of investigation tasks for the most suspicious keywords.\n",
    "- If it appears benign and 'boring', set the verdict to BENIGN, the phase to FINALIZING, and leave the queue empty.\n",
    "Your analysis trail entry should be a concise summary of your decision.\n",
    "\"\"\"\n",
    "\n",
    "# --- 3. Tool Simulation & Helper Functions (Unchanged) ---\n",
    "\n",
    "def run_pdfid_simulation(file_path: str) -> str:\n",
    "    print(f\"[*] SIMULATING 'pdfid' on: {file_path}\")\n",
    "    return \"\"\"\n",
    " PDF Header: %PDF-1.4\n",
    " obj                  10\n",
    " endobj                9\n",
    " stream                3\n",
    " endstream             3\n",
    " xref                  1\n",
    " trailer               1\n",
    " startxref             1\n",
    " /Page                 1\n",
    " /Encrypt              0\n",
    " /JS                   2\n",
    " /JavaScript           2\n",
    " /AA                   1\n",
    " /OpenAction           1\n",
    " /AcroForm             0\n",
    " /JBIG2Decode          0\n",
    " /RichMedia            0\n",
    " /Launch               1\n",
    " /EmbeddedFile         0\n",
    " /XFA                  0\n",
    " /Colors > 2^24        0\n",
    "    \"\"\"\n",
    "\n",
    "def get_file_hash(file_path: str) -> str:\n",
    "    print(f\"[*] SIMULATING hash calculation for: {file_path}\")\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    sha256_hash.update(file_path.encode('utf-8'))\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "# --- 4. LLM-Powered Graph Node ---\n",
    "\n",
    "def triage_node_llm(state: ForensicCaseFile) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    This node uses an LLM to perform triage instead of manual rules.\n",
    "    \"\"\"\n",
    "    file_path = state.file_path\n",
    "    print(\"\\n--- Running LLM-Powered Triage Node ---\")\n",
    "\n",
    "    # 1. Perform initial actions\n",
    "    file_hash = get_file_hash(file_path)\n",
    "    pdfid_output = run_pdfid_simulation(file_path)\n",
    "\n",
    "    # 2. Set up the LLM chain\n",
    "    # NOTE: To run for real, you need an OPENAI_API_KEY in your environment\n",
    "    # and to install langchain-openai (`pip install langchain-openai`)\n",
    "    prompt = ChatPromptTemplate.from_template(TRIAGE_PROMPT_TEMPLATE)\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    structured_llm = llm.with_structured_output(TriageAnalysis)\n",
    "    chain = prompt | structured_llm\n",
    "\n",
    "    # 3. Invoke the LLM\n",
    "    print(\"[*] Asking LLM (Dr. Reed) for analysis...\")\n",
    "    # llm_response = chain.invoke({\"pdfid_output\": pdfid_output}) # <-- REAL LLM CALL\n",
    "\n",
    "    # --- MOCKED LLM CALL FOR RUNNABLE EXAMPLE ---\n",
    "    mock_response_json = {\n",
    "        \"verdict\": \"Suspicious\",\n",
    "        \"phase\": \"Interrogation\",\n",
    "        \"is_suspicious\": True,\n",
    "        \"investigation_queue\": [\n",
    "            {\"object_id\": 0, \"priority\": 1, \"reason\": \"Contains /JS and /JavaScript keywords, indicating active content.\"},\n",
    "            {\"object_id\": 0, \"priority\": 2, \"reason\": \"Contains /OpenAction and /AA keywords, suggesting automatic execution.\"},\n",
    "            {\"object_id\": 0, \"priority\": 3, \"reason\": \"Contains /Launch keyword, a highly suspicious capability.\"}\n",
    "        ],\n",
    "        \"analysis_trail\": \"Initial scan reveals high-potential for action via JavaScript and auto-execution triggers. The file's character is suspect. Suspending innocence and proceeding to interrogation.\",\n",
    "        \"narrative_coherence_notes\": [\"File contains multiple high-risk keywords (/JS, /OpenAction, /Launch) that are incoherent with a simple document's purpose.\"]\n",
    "    }\n",
    "    llm_response = TriageAnalysis(**mock_response_json)\n",
    "    # --- END MOCK ---\n",
    "\n",
    "    print(f\"[*] LLM analysis received. Verdict: {llm_response.verdict}\")\n",
    "\n",
    "    # 4. Prepare state updates from the LLM's structured response\n",
    "    updates = {\n",
    "        \"file_hash_sha256\": file_hash,\n",
    "        \"analysis_trail\": [\n",
    "            f\"Triage started for {file_path} (SHA256: {file_hash[:12]}...).\",\n",
    "            llm_response.analysis_trail # Append the LLM's own log entry\n",
    "        ],\n",
    "        \"verdict\": llm_response.verdict,\n",
    "        \"phase\": llm_response.phase,\n",
    "    }\n",
    "\n",
    "    if llm_response.is_suspicious:\n",
    "        updates[\"investigation_queue\"] = llm_response.investigation_queue\n",
    "    \n",
    "    # Update nested models correctly\n",
    "    updated_evidence = state.evidence.model_copy(deep=True)\n",
    "    updated_evidence.structural_summary = {\n",
    "        line.split()[0]: int(line.split()[1])\n",
    "        for line in pdfid_output.strip().split('\\n')\n",
    "        if line.split() and line.split()[0].startswith('/') and line.split()[1].isdigit()\n",
    "    }\n",
    "\n",
    "    updated_coherence = state.narrative_coherence.model_copy(deep=True)\n",
    "    if llm_response.is_suspicious:\n",
    "        updated_coherence.score = 0.5 # Lower score for suspicious files\n",
    "        updated_coherence.notes.extend(llm_response.narrative_coherence_notes)\n",
    "    \n",
    "    updates[\"evidence\"] = updated_evidence\n",
    "    updates[\"narrative_coherence\"] = updated_coherence\n",
    "    \n",
    "    return updates\n",
    "\n",
    "# --- 5. Graph Definition and Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Setting up Forensic Analysis Graph ---\")\n",
    "    \n",
    "    workflow = StateGraph(ForensicCaseFile)\n",
    "    workflow.add_node(\"triage\", triage_node_llm)\n",
    "    workflow.set_entry_point(\"triage\")\n",
    "    workflow.add_edge(\"triage\", END)\n",
    "    app = workflow.compile()\n",
    "\n",
    "    pdf_to_analyze = \"87c740d2b7c22f9ccabbdef412443d166733d4d925da0e8d6e5b310ccfc89e13.pdf\"\n",
    "    inputs = ForensicCaseFileInput(file_path=pdf_to_analyze)\n",
    "    \n",
    "    final_state_dict = app.invoke(inputs.model_dump())\n",
    "    final_state = ForensicCaseFile(**final_state_dict)\n",
    "\n",
    "    print(\"\\n\\n--- Final Graph State ---\")\n",
    "    print(final_state.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
